# module that pulls data from several sources and generate vulnerability breakdown for subnational SEIR model

import os
import glob
import argparse
import logging
from pathlib import Path
import ast
import itertools
import string

import numpy as np
import pandas as pd
import geopandas as gpd
import rasterio
from rasterio.merge import merge
from rasterio.mask import mask
import fiona

from covid_model_parametrization.exposure import get_output_filename

from covid_model_parametrization import utils
from covid_model_parametrization.config import Config


logger = logging.getLogger(__name__)


def vulnerability(country_iso3, download_ghs=False, config=None):

    # Get config file
    if config is None:
        config = Config()
    parameters = config.parameters[country_iso3]

    # Get input boundary shape file
    input_dir = os.path.join(config.DIR_PATH, config.INPUT_DIR, country_iso3)
    input_shp = os.path.join(input_dir, config.SHAPEFILE_DIR, parameters['admin']['directory'],
                             f'{parameters["admin"]["directory"]}.shp')
    boundaries = gpd.read_file(input_shp).to_crs(config.GHS_CRS)

    # Download the tiles and read them in
    if download_ghs:
        get_ghs_data('SMOD', parameters['ghs'], country_iso3, input_dir, config)
        get_ghs_data('POP', parameters['ghs'], country_iso3, input_dir, config)
    ghs_smod = rasterio.open(os.path.join(input_dir, config.GHS_DIR,
                                          config.OUTPUT_GHS['SMOD'].format(country_iso3=country_iso3)))
    ghs_pop = rasterio.open(os.path.join(input_dir, config.GHS_DIR,
                                         config.OUTPUT_GHS['POP'].format(country_iso3=country_iso3)))

    # adding urban/rural disaggregation data using JRC GHSL input
    logger.info("Calculating urban population fraction")
    boundaries['frac_urban'] = boundaries['geometry'].apply(lambda x: calc_frac_urban(x, ghs_smod, ghs_pop, config))

    # Get food insecurity
    logger.info("Getting food insecurity")
    boundaries = add_food_insecurity(parameters['ipc'], input_dir, boundaries, parameters['admin']['language'], config)

    # Get solid fuels
    if 'solid_fuels' in parameters:
        logger.info("Getting Solid Fuels data")
        boundaries = add_factor_urban_rural(boundaries, 'fossil_fuels',parameters['solid_fuels'])
    else:
        logger.info(f'Solid fuels data not available for country {country_iso3}')
    
    # Get handwashing facilities
    if 'handwashing_facilities' in parameters:
        logger.info("Getting Handwashing facilities data")
        boundaries = add_factor_urban_rural(boundaries, 'handwashing_facilities',parameters['handwashing_facilities'])
    else:
        logger.info(f'Handwashing facilities data not available for country {country_iso3}')

    # Get raised blood pressure
    if 'raised_blood_pressure' in parameters:
        logger.info("Getting Raised Blood Pressure data")
        add_factor_18plus(boundaries, parameters['raised_blood_pressure'], 'raised_blood_pressure', country_iso3, config)
    else:
        logger.info(f'Raised blood pressure data not available for country {country_iso3}')

    # Get raised blood pressure
    if 'diabetes' in parameters:
        logger.info("Getting diabetes data")
        add_factor_18plus(boundaries, parameters['diabetes'], 'diabetes', country_iso3, config)
    else:
        logger.info(f'Diabetes data not available for country {country_iso3}')
    
    # Get smoking
    if 'smoking' in parameters:
        logger.info("Getting smoking data")
        add_factor_18plus(boundaries, parameters['smoking'], 'smoking', country_iso3, config)
    else:
        logger.info(f'Smoking data not available for country {country_iso3}')

    # Write out results
    output_dir = os.path.join(config.DIR_PATH, config.vulnerability_output_dir().format(country_iso3))
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    output_geojson = os.path.join(output_dir, config.VULNERABILITY_FILENAME.format(country_iso3=country_iso3))
    logger.info(f"Saving results to {output_geojson}")
    utils.write_to_geojson(output_geojson, boundaries.to_crs(config.SHP_CRS))


def get_ghs_data(ghs_type, parameters, country_iso3, input_dir, config):
    """
    :param ghs_type: One of either "SMOD" or "POP"
    """
    logger.info(f'Getting GHS data for {ghs_type}')
    download_dir = os.path.join(input_dir, config.GHS_DIR, 'zip')
    Path(download_dir).mkdir(parents=True, exist_ok=True)
    for column, row in [ast.literal_eval(x) for x in parameters['column_row_pairs']]:
        zip_filename = os.path.join(download_dir, f'{ghs_type}_2015_1km_{column}_{row}.zip')
        utils.download_url(f'{config.GHS_URL_BASE}/{config.GHS_URL[ghs_type].format(column=column, row=row)}', zip_filename)
        utils.unzip(zip_filename, download_dir)
    # Make a mosaic
    files_to_mosaic = [rasterio.open(f) for f in glob.glob(os.path.join(download_dir, f'*_{ghs_type}_*.tif'))]
    logger.info(f'Making mosiac of {len(files_to_mosaic)} files')
    mosaic, out_trans = merge(files_to_mosaic)
    out_meta = files_to_mosaic[0].meta.copy()
    out_meta.update({"driver": "GTiff",
                     "height": mosaic.shape[1],
                     "width": mosaic.shape[2],
                     "transform": out_trans})
    output_filepath = os.path.join(input_dir, config.GHS_DIR,
                                   config.OUTPUT_GHS[ghs_type].format(country_iso3=country_iso3))
    with rasterio.open(output_filepath, "w", **out_meta) as dest:
        dest.write(mosaic)
    logger.info(f'Wrote file to {output_filepath}')


def calc_frac_urban(shape, ghs_smod, ghs_pop, config):
    pixels_smod = mask(ghs_smod, [shape])[0].flatten()
    pixels_pop = ghs_pop.read(1).flatten()
    pop_urban = sum(pixels_pop[np.where((pixels_smod >= config.URBAN_MIN_MAX[0]) & (pixels_smod <= config.URBAN_MIN_MAX[1]))])
    pop_rural = sum(pixels_pop[np.where((pixels_smod >= config.RURAL_MIN_MAX[0]) & (pixels_smod <= config.RURAL_MIN_MAX[1]))])
    return pop_urban / (pop_urban + pop_rural)


def add_food_insecurity(parameters, input_dir, boundaries, lang, config):
    admin_level = parameters['admin_level']
    filename = os.path.join(input_dir, config.IPC_DIR, parameters['filename'])
    df_ipc = (pd.read_excel(filename, header=[11], skiprows=[12], nrows=parameters['last_row']-13)
              .rename(columns={'Area': f'ADM{admin_level}', '#': 'Population', '%.5': 'Phase 3+'})
              .loc[:, ['Country', f'ADM{admin_level}', 'Population', 'Phase 3+']])
    # In general the COD boundaries have title style capitalization
    for column in ['Country', f'ADM{admin_level}']:
        df_ipc[column] = df_ipc[column].apply(lambda x: string.capwords(x) if type(x) == str else x)
    # Do any name replacements
    if 'replace_dict' in parameters:
        df_ipc = df_ipc.replace(parameters['replace_dict'])
    # Check that admin level names in the IPC data are all reasonable
    misspelled_names = np.setdiff1d(list(df_ipc[f'ADM{admin_level}'].dropna()),
                                    list(boundaries[f'ADM{admin_level}_{lang}'].dropna()))
    if misspelled_names.size > 0:
        logger.warning(f'The following admin {admin_level} regions from the IPC file are not found '
                       f'in the boundaries file: {misspelled_names}')
    # Make a data frame of just ADM1
    if admin_level == 2:
        df_ipc = df_ipc.rename(columns={'Country': 'ADM1'})
        # This is mostly for Sudan because of multiple admin 2 boundary names
        if 'replace_dict_boundaries' in parameters:
            for admin1, admin2_list in parameters['replace_dict_boundaries'].items():
                logger.info(f'Temporarily replacing {admin1}/{admin2_list[0]} with {admin2_list[1]}')
                boundaries.loc[(boundaries[f'ADM2_{lang}'] == admin1) &
                               (boundaries[f'ADM2_{lang}'] == admin2_list[0]), f'ADM2_{lang}'] = admin2_list[1]
        # Also check admin level names for admin 1
        misspelled_names = np.setdiff1d(list(df_ipc[f'ADM1'].dropna()),
                                        list(boundaries[f'ADM1_{lang}'].dropna()))
        if misspelled_names.size > 0:
            logger.warning(f'The following admin 1 regions from the IPC file are not found '
                           f'in the boundaries file: {misspelled_names}')
        # First join on admin 2, then on admin 1
        boundaries = boundaries.merge(df_ipc[[f'ADM1', 'Phase 3+']],
                                      left_on=f'ADM1_{lang}', right_on='ADM1', how='left')
        boundaries = boundaries.merge(df_ipc[[f'ADM2', 'Phase 3+']],
                                      left_on=f'ADM2_{lang}', right_on='ADM2', how='left', suffixes=('_1', '_2'))
        # Replace adm1 vals with adm2
        boundaries['Phase 3+'] = boundaries['Phase 3+_2'].combine_first(boundaries['Phase 3+_1'])
        boundaries = boundaries.drop(columns=['ADM1', 'ADM2', 'Phase 3+_1', 'Phase 3+_2'])
        # Finally put back the original admin 2 name
        if 'replace_dict_boundaries' in parameters:
            for admin1, admin2_list in parameters['replace_dict_boundaries'].items():
                logger.info(f'Putting {admin1}/{admin2_list[1]} back to {admin2_list[0]}')
                boundaries.loc[(boundaries[f'ADM2_{lang}'] == admin1) &
                               (boundaries[f'ADM2_{lang}'] == admin2_list[1]), f'ADM2_{lang}'] = admin2_list[0]
    elif admin_level == 1:
        df_adm1 = pd.DataFrame(columns=['ADM1', 'Phase 3+'])
        df_adm1['ADM1'] = sorted(boundaries[f'ADM1_{lang}'].unique())
        # For each province, get the total insecurity, or the urban / rural if it's split
        for index, row in df_adm1.iterrows():
            adm1 = row['ADM1']
            # Check if divided by urban / rural
            if f'{adm1} Urban' in list(df_ipc['ADM1']):
                row_urban = df_ipc.loc[df_ipc['ADM1'] == f'{adm1} Urban'].iloc[0]
                row_rural = df_ipc.loc[df_ipc['ADM1'] == f'{adm1}'].iloc[0]
                phase_3 = (row_urban['Population'] * row_urban['Phase 3+'] +
                           row_rural['Population'] * row_rural['Phase 3+']) /\
                           (row_urban['Population'] + row_rural['Population'])
            else:
                phase_3 = df_ipc.loc[df_ipc['ADM1'] == adm1, 'Phase 3+'].iloc[0]
            df_adm1.loc[index, 'Phase 3+'] = phase_3
        boundaries = boundaries.merge(df_adm1, left_on=f'ADM1_{lang}', right_on='ADM1', how='left')

    return boundaries


def add_factor_urban_rural(boundaries, factor_name, parameters):
    boundaries[factor_name] = boundaries['frac_urban'].apply(lambda x: x * parameters['frac_urban'] +
                                                                        (1 - x) * parameters['frac_rural'])
    return boundaries


def add_factor_18plus(boundaries, fraction, factor_name, country_iso3, config):
    # TODO we could add disaggregation by gender
    try:
        exposure_gdf=gpd.read_file(get_output_filename(country_iso3, config))
        # consider only 18+
        gender_age_groups=list(itertools.product(config.GENDER_CLASSES, [a for a in config.AGE_CLASSES if a > 18]))
        gender_age_group_names=['{}_{}'.format(gender_age_group[0], gender_age_group[1])\
            for gender_age_group in gender_age_groups]
        pop18_frac=exposure_gdf.loc[:,gender_age_group_names].sum(axis=1)/exposure_gdf['tot_sad']
        boundaries[factor_name]=pop18_frac*fraction
    except fiona.errors.DriverError:
        logger.info('Exposure data not available, cannot calculate fraction 18+')
    return boundaries
